{"ast":null,"code":"// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT License.\nimport { ChangeFeedIterator } from \"../../ChangeFeedIterator\";\nimport { getIdFromLink, getPathFromLink, isItemResourceValid, ResourceType, StatusCodes, SubStatusCodes } from \"../../common\";\nimport { extractPartitionKeys, setPartitionKeyIfUndefined } from \"../../extractPartitionKey\";\nimport { QueryIterator } from \"../../queryIterator\";\nimport { Item } from \"./Item\";\nimport { ItemResponse } from \"./ItemResponse\";\nimport { isKeyInRange, prepareOperations, decorateBatchOperation, splitBatchBasedOnBodySize } from \"../../utils/batch\";\nimport { assertNotUndefined, isPrimitivePartitionKeyValue } from \"../../utils/typeChecks\";\nimport { hashPartitionKey } from \"../../utils/hashing/hash\";\nimport { PartitionKeyRangeCache, QueryRange } from \"../../routing\";\nimport { changeFeedIteratorBuilder } from \"../../client/ChangeFeed\";\nimport { validateChangeFeedIteratorOptions } from \"../../client/ChangeFeed/changeFeedUtils\";\nimport { DiagnosticNodeType } from \"../../diagnostics/DiagnosticNodeInternal\";\nimport { getEmptyCosmosDiagnostics, withDiagnostics, addDignosticChild } from \"../../utils/diagnostics\";\nimport { randomUUID } from \"@azure/core-util\";\nimport { readPartitionKeyDefinition } from \"../ClientUtils\";\n/**\n * @hidden\n */\nfunction isChangeFeedOptions(options) {\n  return options && !(isPrimitivePartitionKeyValue(options) || Array.isArray(options));\n}\n/**\n * Operations for creating new items, and reading/querying all items\n *\n * @see {@link Item} for reading, replacing, or deleting an existing container; use `.item(id)`.\n */\nexport class Items {\n  /**\n   * Create an instance of {@link Items} linked to the parent {@link Container}.\n   * @param container - The parent container.\n   * @hidden\n   */\n  constructor(container, clientContext) {\n    this.container = container;\n    this.clientContext = clientContext;\n    this.partitionKeyRangeCache = new PartitionKeyRangeCache(this.clientContext);\n  }\n  query(query, options = {}) {\n    const path = getPathFromLink(this.container.url, ResourceType.item);\n    const id = getIdFromLink(this.container.url);\n    const fetchFunction = async (diagnosticNode, innerOptions, correlatedActivityId) => {\n      const response = await this.clientContext.queryFeed({\n        path,\n        resourceType: ResourceType.item,\n        resourceId: id,\n        resultFn: result => result ? result.Documents : [],\n        query,\n        options: innerOptions,\n        partitionKey: options.partitionKey,\n        diagnosticNode,\n        correlatedActivityId: correlatedActivityId\n      });\n      return response;\n    };\n    return new QueryIterator(this.clientContext, query, options, fetchFunction, this.container.url, ResourceType.item);\n  }\n  readChangeFeed(partitionKeyOrChangeFeedOptions, changeFeedOptions) {\n    if (isChangeFeedOptions(partitionKeyOrChangeFeedOptions)) {\n      return this.changeFeed(partitionKeyOrChangeFeedOptions);\n    } else {\n      return this.changeFeed(partitionKeyOrChangeFeedOptions, changeFeedOptions);\n    }\n  }\n  changeFeed(partitionKeyOrChangeFeedOptions, changeFeedOptions) {\n    let partitionKey;\n    if (!changeFeedOptions && isChangeFeedOptions(partitionKeyOrChangeFeedOptions)) {\n      partitionKey = undefined;\n      changeFeedOptions = partitionKeyOrChangeFeedOptions;\n    } else if (partitionKeyOrChangeFeedOptions !== undefined && !isChangeFeedOptions(partitionKeyOrChangeFeedOptions)) {\n      partitionKey = partitionKeyOrChangeFeedOptions;\n    }\n    if (!changeFeedOptions) {\n      changeFeedOptions = {};\n    }\n    const path = getPathFromLink(this.container.url, ResourceType.item);\n    const id = getIdFromLink(this.container.url);\n    return new ChangeFeedIterator(this.clientContext, id, path, partitionKey, changeFeedOptions);\n  }\n  /**\n   * Returns an iterator to iterate over pages of changes. The iterator returned can be used to fetch changes for a single partition key, feed range or an entire container.\n   */\n  getChangeFeedIterator(changeFeedIteratorOptions) {\n    const cfOptions = changeFeedIteratorOptions !== undefined ? changeFeedIteratorOptions : {};\n    validateChangeFeedIteratorOptions(cfOptions);\n    const iterator = changeFeedIteratorBuilder(cfOptions, this.clientContext, this.container, this.partitionKeyRangeCache);\n    return iterator;\n  }\n  readAll(options) {\n    return this.query(\"SELECT * from c\", options);\n  }\n  /**\n   * Create an item.\n   *\n   * Any provided type, T, is not necessarily enforced by the SDK.\n   * You may get more or less properties and it's up to your logic to enforce it.\n   *\n   * There is no set schema for JSON items. They may contain any number of custom properties.\n   *\n   * @param body - Represents the body of the item. Can contain any number of user defined properties.\n   * @param options - Used for modifying the request (for instance, specifying the partition key).\n   */\n  async create(body, options = {}) {\n    // Generate random document id if the id is missing in the payload and\n    // options.disableAutomaticIdGeneration != true\n    return withDiagnostics(async diagnosticNode => {\n      if ((body.id === undefined || body.id === \"\") && !options.disableAutomaticIdGeneration) {\n        body.id = randomUUID();\n      }\n      const partitionKeyDefinition = await readPartitionKeyDefinition(diagnosticNode, this.container);\n      const partitionKey = extractPartitionKeys(body, partitionKeyDefinition);\n      const err = {};\n      if (!isItemResourceValid(body, err)) {\n        throw err;\n      }\n      const path = getPathFromLink(this.container.url, ResourceType.item);\n      const id = getIdFromLink(this.container.url);\n      const response = await this.clientContext.create({\n        body,\n        path,\n        resourceType: ResourceType.item,\n        resourceId: id,\n        diagnosticNode,\n        options,\n        partitionKey\n      });\n      const ref = new Item(this.container, response.result.id, this.clientContext, partitionKey);\n      return new ItemResponse(response.result, response.headers, response.code, response.substatus, ref, getEmptyCosmosDiagnostics());\n    }, this.clientContext);\n  }\n  async upsert(body, options = {}) {\n    return withDiagnostics(async diagnosticNode => {\n      // Generate random document id if the id is missing in the payload and\n      // options.disableAutomaticIdGeneration != true\n      if ((body.id === undefined || body.id === \"\") && !options.disableAutomaticIdGeneration) {\n        body.id = randomUUID();\n      }\n      const partitionKeyDefinition = await readPartitionKeyDefinition(diagnosticNode, this.container);\n      const partitionKey = extractPartitionKeys(body, partitionKeyDefinition);\n      const err = {};\n      if (!isItemResourceValid(body, err)) {\n        throw err;\n      }\n      const path = getPathFromLink(this.container.url, ResourceType.item);\n      const id = getIdFromLink(this.container.url);\n      const response = await this.clientContext.upsert({\n        body,\n        path,\n        resourceType: ResourceType.item,\n        resourceId: id,\n        options,\n        partitionKey,\n        diagnosticNode\n      });\n      const ref = new Item(this.container, response.result.id, this.clientContext, partitionKey);\n      return new ItemResponse(response.result, response.headers, response.code, response.substatus, ref, getEmptyCosmosDiagnostics());\n    }, this.clientContext);\n  }\n  /**\n   * Execute bulk operations on items.\n   *\n   * Bulk takes an array of Operations which are typed based on what the operation does.\n   * The choices are: Create, Upsert, Read, Replace, and Delete\n   *\n   * Usage example:\n   * ```typescript\n   * // partitionKey is optional at the top level if present in the resourceBody\n   * const operations: OperationInput[] = [\n   *    {\n   *       operationType: \"Create\",\n   *       resourceBody: { id: \"doc1\", name: \"sample\", key: \"A\" }\n   *    },\n   *    {\n   *       operationType: \"Upsert\",\n   *       partitionKey: 'A',\n   *       resourceBody: { id: \"doc2\", name: \"other\", key: \"A\" }\n   *    }\n   * ]\n   *\n   * await database.container.items.bulk(operations)\n   * ```\n   *\n   * @param operations - List of operations. Limit 100\n   * @param bulkOptions - Optional options object to modify bulk behavior. Pass \\{ continueOnError: false \\} to stop executing operations when one fails. (Defaults to true)\n   * @param options - Used for modifying the request.\n   */\n  async bulk(operations, bulkOptions, options) {\n    return withDiagnostics(async diagnosticNode => {\n      const partitionKeyRanges = (await this.partitionKeyRangeCache.onCollectionRoutingMap(this.container.url, diagnosticNode)).getOrderedParitionKeyRanges();\n      const partitionKeyDefinition = await readPartitionKeyDefinition(diagnosticNode, this.container);\n      const batches = partitionKeyRanges.map(keyRange => {\n        return {\n          min: keyRange.minInclusive,\n          max: keyRange.maxExclusive,\n          rangeId: keyRange.id,\n          indexes: [],\n          operations: []\n        };\n      });\n      this.groupOperationsBasedOnPartitionKey(operations, partitionKeyDefinition, options, batches);\n      const path = getPathFromLink(this.container.url, ResourceType.item);\n      const orderedResponses = [];\n      // split batches based on cumulative size of operations\n      const batchMap = batches.filter(batch => batch.operations.length).flatMap(batch => splitBatchBasedOnBodySize(batch));\n      await Promise.all(this.executeBatchOperations(batchMap, path, bulkOptions, options, diagnosticNode, orderedResponses, partitionKeyDefinition));\n      const response = orderedResponses;\n      response.diagnostics = diagnosticNode.toDiagnostic(this.clientContext.getClientConfig());\n      return response;\n    }, this.clientContext);\n  }\n  executeBatchOperations(batchMap, path, bulkOptions, options, diagnosticNode, orderedResponses, partitionKeyDefinition) {\n    return batchMap.map(async batch => {\n      if (batch.operations.length > 100) {\n        throw new Error(\"Cannot run bulk request with more than 100 operations per partition\");\n      }\n      try {\n        const response = await addDignosticChild(async childNode => this.clientContext.bulk({\n          body: batch.operations,\n          partitionKeyRangeId: batch.rangeId,\n          path,\n          resourceId: this.container.url,\n          bulkOptions,\n          options,\n          diagnosticNode: childNode\n        }), diagnosticNode, DiagnosticNodeType.BATCH_REQUEST);\n        response.result.forEach((operationResponse, index) => {\n          orderedResponses[batch.indexes[index]] = operationResponse;\n        });\n      } catch (err) {\n        // In the case of 410 errors, we need to recompute the partition key ranges\n        // and redo the batch request, however, 410 errors occur for unsupported\n        // partition key types as well since we don't support them, so for now we throw\n        if (err.code === StatusCodes.Gone) {\n          const isPartitionSplit = err.substatus === SubStatusCodes.PartitionKeyRangeGone || err.substatus === SubStatusCodes.CompletingSplit;\n          if (isPartitionSplit) {\n            const queryRange = new QueryRange(batch.min, batch.max, true, false);\n            const overlappingRanges = await this.partitionKeyRangeCache.getOverlappingRanges(this.container.url, queryRange, diagnosticNode, true);\n            if (overlappingRanges.length < 1) {\n              throw new Error(\"Partition split/merge detected but no overlapping ranges found.\");\n            }\n            // Handles both merge (overlappingRanges.length === 1) and split (overlappingRanges.length > 1) cases.\n            if (overlappingRanges.length >= 1) {\n              // const splitBatches: Batch[] = [];\n              const newBatches = this.createNewBatches(overlappingRanges, batch, partitionKeyDefinition);\n              await Promise.all(this.executeBatchOperations(newBatches, path, bulkOptions, options, diagnosticNode, orderedResponses, partitionKeyDefinition));\n            }\n          } else {\n            throw new Error(\"Partition key error. An operation has an unsupported partitionKey type\" + err.message);\n          }\n        } else {\n          throw new Error(`Bulk request errored with: ${err.message}`);\n        }\n      }\n    });\n  }\n  /**\n   * Function to create new batches based of partition key Ranges.\n   *\n   * @param overlappingRanges - Overlapping partition key ranges.\n   * @param batch - Batch to be split.\n   * @param partitionKeyDefinition - PartitionKey definition of container.\n   * @returns Array of new batches.\n   */\n  createNewBatches(overlappingRanges, batch, partitionKeyDefinition) {\n    const newBatches = overlappingRanges.map(keyRange => {\n      return {\n        min: keyRange.minInclusive,\n        max: keyRange.maxExclusive,\n        rangeId: keyRange.id,\n        indexes: [],\n        operations: []\n      };\n    });\n    let indexValue = 0;\n    batch.operations.forEach(operation => {\n      const partitionKey = JSON.parse(operation.partitionKey);\n      const hashed = hashPartitionKey(assertNotUndefined(partitionKey, \"undefined value for PartitionKey is not expected during grouping of bulk operations.\"), partitionKeyDefinition);\n      const batchForKey = assertNotUndefined(newBatches.find(newBatch => {\n        return isKeyInRange(newBatch.min, newBatch.max, hashed);\n      }), \"No suitable Batch found.\");\n      batchForKey.operations.push(operation);\n      batchForKey.indexes.push(batch.indexes[indexValue]);\n      indexValue++;\n    });\n    return newBatches;\n  }\n  /**\n   * Function to create batches based of partition key Ranges.\n   * @param operations - operations to group\n   * @param partitionDefinition - PartitionKey definition of container.\n   * @param options - Request options for bulk request.\n   * @param batches - Groups to be filled with operations.\n   */\n  groupOperationsBasedOnPartitionKey(operations, partitionDefinition, options, batches) {\n    operations.forEach((operationInput, index) => {\n      const {\n        operation,\n        partitionKey\n      } = prepareOperations(operationInput, partitionDefinition, options);\n      const hashed = hashPartitionKey(assertNotUndefined(partitionKey, \"undefined value for PartitionKey is not expected during grouping of bulk operations.\"), partitionDefinition);\n      const batchForKey = assertNotUndefined(batches.find(batch => {\n        return isKeyInRange(batch.min, batch.max, hashed);\n      }), \"No suitable Batch found.\");\n      batchForKey.operations.push(operation);\n      batchForKey.indexes.push(index);\n    });\n  }\n  /**\n   * Execute transactional batch operations on items.\n   *\n   * Batch takes an array of Operations which are typed based on what the operation does. Batch is transactional and will rollback all operations if one fails.\n   * The choices are: Create, Upsert, Read, Replace, and Delete\n   *\n   * Usage example:\n   * ```typescript\n   * // The partitionKey is a required second argument. If it’s undefined, it defaults to the expected partition key format.\n   * const operations: OperationInput[] = [\n   *    {\n   *       operationType: \"Create\",\n   *       resourceBody: { id: \"doc1\", name: \"sample\", key: \"A\" }\n   *    },\n   *    {\n   *       operationType: \"Upsert\",\n   *       resourceBody: { id: \"doc2\", name: \"other\", key: \"A\" }\n   *    }\n   * ]\n   *\n   * await database.container.items.batch(operations, \"A\")\n   * ```\n   *\n   * @param operations - List of operations. Limit 100\n   * @param options - Used for modifying the request\n   */\n  async batch(operations, partitionKey, options) {\n    return withDiagnostics(async diagnosticNode => {\n      operations.map(operation => decorateBatchOperation(operation, options));\n      partitionKey = await setPartitionKeyIfUndefined(diagnosticNode, this.container, partitionKey);\n      const path = getPathFromLink(this.container.url, ResourceType.item);\n      if (operations.length > 100) {\n        throw new Error(\"Cannot run batch request with more than 100 operations per partition\");\n      }\n      try {\n        const response = await this.clientContext.batch({\n          body: operations,\n          partitionKey,\n          path,\n          resourceId: this.container.url,\n          options,\n          diagnosticNode\n        });\n        return response;\n      } catch (err) {\n        throw new Error(`Batch request error: ${err.message}`);\n      }\n    }, this.clientContext);\n  }\n}","map":{"version":3,"names":["ChangeFeedIterator","getIdFromLink","getPathFromLink","isItemResourceValid","ResourceType","StatusCodes","SubStatusCodes","extractPartitionKeys","setPartitionKeyIfUndefined","QueryIterator","Item","ItemResponse","isKeyInRange","prepareOperations","decorateBatchOperation","splitBatchBasedOnBodySize","assertNotUndefined","isPrimitivePartitionKeyValue","hashPartitionKey","PartitionKeyRangeCache","QueryRange","changeFeedIteratorBuilder","validateChangeFeedIteratorOptions","DiagnosticNodeType","getEmptyCosmosDiagnostics","withDiagnostics","addDignosticChild","randomUUID","readPartitionKeyDefinition","isChangeFeedOptions","options","Array","isArray","Items","constructor","container","clientContext","partitionKeyRangeCache","query","path","url","item","id","fetchFunction","diagnosticNode","innerOptions","correlatedActivityId","response","queryFeed","resourceType","resourceId","resultFn","result","Documents","partitionKey","readChangeFeed","partitionKeyOrChangeFeedOptions","changeFeedOptions","changeFeed","undefined","getChangeFeedIterator","changeFeedIteratorOptions","cfOptions","iterator","readAll","create","body","disableAutomaticIdGeneration","partitionKeyDefinition","err","ref","headers","code","substatus","upsert","bulk","operations","bulkOptions","partitionKeyRanges","onCollectionRoutingMap","getOrderedParitionKeyRanges","batches","map","keyRange","min","minInclusive","max","maxExclusive","rangeId","indexes","groupOperationsBasedOnPartitionKey","orderedResponses","batchMap","filter","batch","length","flatMap","Promise","all","executeBatchOperations","diagnostics","toDiagnostic","getClientConfig","Error","childNode","partitionKeyRangeId","BATCH_REQUEST","forEach","operationResponse","index","Gone","isPartitionSplit","PartitionKeyRangeGone","CompletingSplit","queryRange","overlappingRanges","getOverlappingRanges","newBatches","createNewBatches","message","indexValue","operation","JSON","parse","hashed","batchForKey","find","newBatch","push","partitionDefinition","operationInput"],"sources":["/Users/ajitpawar/microsoft/bap/POCs/Scenario_checker_for_maker/mcs-scenario-checker-for-maker/node_modules/@azure/cosmos/src/client/Item/Items.ts"],"sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT License.\n\nimport { ChangeFeedIterator } from \"../../ChangeFeedIterator\";\nimport type { ChangeFeedOptions } from \"../../ChangeFeedOptions\";\nimport type { ClientContext } from \"../../ClientContext\";\nimport {\n  getIdFromLink,\n  getPathFromLink,\n  isItemResourceValid,\n  ResourceType,\n  StatusCodes,\n  SubStatusCodes,\n} from \"../../common\";\nimport { extractPartitionKeys, setPartitionKeyIfUndefined } from \"../../extractPartitionKey\";\nimport type { FetchFunctionCallback, SqlQuerySpec } from \"../../queryExecutionContext\";\nimport { QueryIterator } from \"../../queryIterator\";\nimport type { FeedOptions, RequestOptions, Response } from \"../../request\";\nimport type { Container, PartitionKeyRange } from \"../Container\";\nimport { Item } from \"./Item\";\nimport type { ItemDefinition } from \"./ItemDefinition\";\nimport { ItemResponse } from \"./ItemResponse\";\nimport type {\n  Batch,\n  OperationResponse,\n  OperationInput,\n  BulkOptions,\n  BulkOperationResponse,\n} from \"../../utils/batch\";\nimport {\n  isKeyInRange,\n  prepareOperations,\n  decorateBatchOperation,\n  splitBatchBasedOnBodySize,\n} from \"../../utils/batch\";\nimport { assertNotUndefined, isPrimitivePartitionKeyValue } from \"../../utils/typeChecks\";\nimport { hashPartitionKey } from \"../../utils/hashing/hash\";\nimport type { PartitionKey, PartitionKeyDefinition } from \"../../documents\";\nimport { PartitionKeyRangeCache, QueryRange } from \"../../routing\";\nimport type {\n  ChangeFeedPullModelIterator,\n  ChangeFeedIteratorOptions,\n} from \"../../client/ChangeFeed\";\nimport { changeFeedIteratorBuilder } from \"../../client/ChangeFeed\";\nimport { validateChangeFeedIteratorOptions } from \"../../client/ChangeFeed/changeFeedUtils\";\nimport type { DiagnosticNodeInternal } from \"../../diagnostics/DiagnosticNodeInternal\";\nimport { DiagnosticNodeType } from \"../../diagnostics/DiagnosticNodeInternal\";\nimport {\n  getEmptyCosmosDiagnostics,\n  withDiagnostics,\n  addDignosticChild,\n} from \"../../utils/diagnostics\";\nimport { randomUUID } from \"@azure/core-util\";\nimport { readPartitionKeyDefinition } from \"../ClientUtils\";\n\n/**\n * @hidden\n */\nfunction isChangeFeedOptions(options: unknown): options is ChangeFeedOptions {\n  return options && !(isPrimitivePartitionKeyValue(options) || Array.isArray(options));\n}\n\n/**\n * Operations for creating new items, and reading/querying all items\n *\n * @see {@link Item} for reading, replacing, or deleting an existing container; use `.item(id)`.\n */\nexport class Items {\n  private partitionKeyRangeCache: PartitionKeyRangeCache;\n  /**\n   * Create an instance of {@link Items} linked to the parent {@link Container}.\n   * @param container - The parent container.\n   * @hidden\n   */\n  constructor(\n    public readonly container: Container,\n    private readonly clientContext: ClientContext,\n  ) {\n    this.partitionKeyRangeCache = new PartitionKeyRangeCache(this.clientContext);\n  }\n\n  /**\n   * Queries all items.\n   * @param query - Query configuration for the operation. See {@link SqlQuerySpec} for more info on how to configure a query.\n   * @param options - Used for modifying the request (for instance, specifying the partition key).\n   * @example Read all items to array.\n   * ```typescript\n   * const querySpec: SqlQuerySpec = {\n   *   query: \"SELECT * FROM Families f WHERE f.lastName = @lastName\",\n   *   parameters: [\n   *     {name: \"@lastName\", value: \"Hendricks\"}\n   *   ]\n   * };\n   * const {result: items} = await items.query(querySpec).fetchAll();\n   * ```\n   */\n  public query(query: string | SqlQuerySpec, options?: FeedOptions): QueryIterator<any>;\n  /**\n   * Queries all items.\n   * @param query - Query configuration for the operation. See {@link SqlQuerySpec} for more info on how to configure a query.\n   * @param options - Used for modifying the request (for instance, specifying the partition key).\n   * @example Read all items to array.\n   * ```typescript\n   * const querySpec: SqlQuerySpec = {\n   *   query: \"SELECT firstname FROM Families f WHERE f.lastName = @lastName\",\n   *   parameters: [\n   *     {name: \"@lastName\", value: \"Hendricks\"}\n   *   ]\n   * };\n   * const {result: items} = await items.query<{firstName: string}>(querySpec).fetchAll();\n   * ```\n   */\n  public query<T>(query: string | SqlQuerySpec, options?: FeedOptions): QueryIterator<T>;\n  public query<T>(query: string | SqlQuerySpec, options: FeedOptions = {}): QueryIterator<T> {\n    const path = getPathFromLink(this.container.url, ResourceType.item);\n    const id = getIdFromLink(this.container.url);\n\n    const fetchFunction: FetchFunctionCallback = async (\n      diagnosticNode: DiagnosticNodeInternal,\n      innerOptions: FeedOptions,\n      correlatedActivityId: string,\n    ) => {\n      const response = await this.clientContext.queryFeed({\n        path,\n        resourceType: ResourceType.item,\n        resourceId: id,\n        resultFn: (result) => (result ? result.Documents : []),\n        query,\n        options: innerOptions,\n        partitionKey: options.partitionKey,\n        diagnosticNode,\n        correlatedActivityId: correlatedActivityId,\n      });\n      return response;\n    };\n\n    return new QueryIterator(\n      this.clientContext,\n      query,\n      options,\n      fetchFunction,\n      this.container.url,\n      ResourceType.item,\n    );\n  }\n\n  /**\n   * Create a `ChangeFeedIterator` to iterate over pages of changes\n   *\n   * @deprecated Use `changeFeed` instead.\n   *\n   * @example Read from the beginning of the change feed.\n   * ```javascript\n   * const iterator = items.readChangeFeed({ startFromBeginning: true });\n   * const firstPage = await iterator.fetchNext();\n   * const firstPageResults = firstPage.result\n   * const secondPage = await iterator.fetchNext();\n   * ```\n   */\n  public readChangeFeed(\n    partitionKey: PartitionKey,\n    changeFeedOptions?: ChangeFeedOptions,\n  ): ChangeFeedIterator<any>;\n  /**\n   * Create a `ChangeFeedIterator` to iterate over pages of changes\n   * @deprecated Use `changeFeed` instead.\n   *\n   */\n  public readChangeFeed(changeFeedOptions?: ChangeFeedOptions): ChangeFeedIterator<any>;\n  /**\n   * Create a `ChangeFeedIterator` to iterate over pages of changes\n   * @deprecated Use `changeFeed` instead.\n   */\n  public readChangeFeed<T>(\n    partitionKey: PartitionKey,\n    changeFeedOptions?: ChangeFeedOptions,\n  ): ChangeFeedIterator<T>;\n  /**\n   * Create a `ChangeFeedIterator` to iterate over pages of changes\n   * @deprecated Use `changeFeed` instead.\n   */\n  public readChangeFeed<T>(changeFeedOptions?: ChangeFeedOptions): ChangeFeedIterator<T>;\n  public readChangeFeed<T>(\n    partitionKeyOrChangeFeedOptions?: PartitionKey | ChangeFeedOptions,\n    changeFeedOptions?: ChangeFeedOptions,\n  ): ChangeFeedIterator<T> {\n    if (isChangeFeedOptions(partitionKeyOrChangeFeedOptions)) {\n      return this.changeFeed(partitionKeyOrChangeFeedOptions);\n    } else {\n      return this.changeFeed(partitionKeyOrChangeFeedOptions, changeFeedOptions);\n    }\n  }\n\n  /**\n   * Create a `ChangeFeedIterator` to iterate over pages of changes\n   *\n   * @example Read from the beginning of the change feed.\n   * ```javascript\n   * const iterator = items.readChangeFeed({ startFromBeginning: true });\n   * const firstPage = await iterator.fetchNext();\n   * const firstPageResults = firstPage.result\n   * const secondPage = await iterator.fetchNext();\n   * ```\n   */\n  public changeFeed(\n    partitionKey: PartitionKey,\n    changeFeedOptions?: ChangeFeedOptions,\n  ): ChangeFeedIterator<any>;\n  /**\n   * Create a `ChangeFeedIterator` to iterate over pages of changes\n   */\n  public changeFeed(changeFeedOptions?: ChangeFeedOptions): ChangeFeedIterator<any>;\n  /**\n   * Create a `ChangeFeedIterator` to iterate over pages of changes\n   */\n  public changeFeed<T>(\n    partitionKey: PartitionKey,\n    changeFeedOptions?: ChangeFeedOptions,\n  ): ChangeFeedIterator<T>;\n  /**\n   * Create a `ChangeFeedIterator` to iterate over pages of changes\n   */\n  public changeFeed<T>(changeFeedOptions?: ChangeFeedOptions): ChangeFeedIterator<T>;\n  public changeFeed<T>(\n    partitionKeyOrChangeFeedOptions?: PartitionKey | ChangeFeedOptions,\n    changeFeedOptions?: ChangeFeedOptions,\n  ): ChangeFeedIterator<T> {\n    let partitionKey: PartitionKey;\n    if (!changeFeedOptions && isChangeFeedOptions(partitionKeyOrChangeFeedOptions)) {\n      partitionKey = undefined;\n      changeFeedOptions = partitionKeyOrChangeFeedOptions;\n    } else if (\n      partitionKeyOrChangeFeedOptions !== undefined &&\n      !isChangeFeedOptions(partitionKeyOrChangeFeedOptions)\n    ) {\n      partitionKey = partitionKeyOrChangeFeedOptions;\n    }\n\n    if (!changeFeedOptions) {\n      changeFeedOptions = {};\n    }\n\n    const path = getPathFromLink(this.container.url, ResourceType.item);\n    const id = getIdFromLink(this.container.url);\n    return new ChangeFeedIterator<T>(this.clientContext, id, path, partitionKey, changeFeedOptions);\n  }\n\n  /**\n   * Returns an iterator to iterate over pages of changes. The iterator returned can be used to fetch changes for a single partition key, feed range or an entire container.\n   */\n  public getChangeFeedIterator<T>(\n    changeFeedIteratorOptions?: ChangeFeedIteratorOptions,\n  ): ChangeFeedPullModelIterator<T> {\n    const cfOptions = changeFeedIteratorOptions !== undefined ? changeFeedIteratorOptions : {};\n    validateChangeFeedIteratorOptions(cfOptions);\n    const iterator = changeFeedIteratorBuilder(\n      cfOptions,\n      this.clientContext,\n      this.container,\n      this.partitionKeyRangeCache,\n    );\n    return iterator;\n  }\n\n  /**\n   * Read all items.\n   *\n   * There is no set schema for JSON items. They may contain any number of custom properties.\n   *\n   * @param options - Used for modifying the request (for instance, specifying the partition key).\n   * @example Read all items to array.\n   * ```typescript\n   * const {body: containerList} = await items.readAll().fetchAll();\n   * ```\n   */\n  public readAll(options?: FeedOptions): QueryIterator<ItemDefinition>;\n  /**\n   * Read all items.\n   *\n   * Any provided type, T, is not necessarily enforced by the SDK.\n   * You may get more or less properties and it's up to your logic to enforce it.\n   *\n   * There is no set schema for JSON items. They may contain any number of custom properties.\n   *\n   * @param options - Used for modifying the request (for instance, specifying the partition key).\n   * @example Read all items to array.\n   * ```typescript\n   * const {body: containerList} = await items.readAll().fetchAll();\n   * ```\n   */\n  public readAll<T extends ItemDefinition>(options?: FeedOptions): QueryIterator<T>;\n  public readAll<T extends ItemDefinition>(options?: FeedOptions): QueryIterator<T> {\n    return this.query<T>(\"SELECT * from c\", options);\n  }\n\n  /**\n   * Create an item.\n   *\n   * Any provided type, T, is not necessarily enforced by the SDK.\n   * You may get more or less properties and it's up to your logic to enforce it.\n   *\n   * There is no set schema for JSON items. They may contain any number of custom properties.\n   *\n   * @param body - Represents the body of the item. Can contain any number of user defined properties.\n   * @param options - Used for modifying the request (for instance, specifying the partition key).\n   */\n  public async create<T extends ItemDefinition = any>(\n    body: T,\n    options: RequestOptions = {},\n  ): Promise<ItemResponse<T>> {\n    // Generate random document id if the id is missing in the payload and\n    // options.disableAutomaticIdGeneration != true\n\n    return withDiagnostics(async (diagnosticNode: DiagnosticNodeInternal) => {\n      if ((body.id === undefined || body.id === \"\") && !options.disableAutomaticIdGeneration) {\n        body.id = randomUUID();\n      }\n      const partitionKeyDefinition = await readPartitionKeyDefinition(\n        diagnosticNode,\n        this.container,\n      );\n      const partitionKey = extractPartitionKeys(body, partitionKeyDefinition);\n\n      const err = {};\n      if (!isItemResourceValid(body, err)) {\n        throw err;\n      }\n\n      const path = getPathFromLink(this.container.url, ResourceType.item);\n      const id = getIdFromLink(this.container.url);\n\n      const response = await this.clientContext.create<T>({\n        body,\n        path,\n        resourceType: ResourceType.item,\n        resourceId: id,\n        diagnosticNode,\n        options,\n        partitionKey,\n      });\n\n      const ref = new Item(\n        this.container,\n        (response.result as any).id,\n        this.clientContext,\n        partitionKey,\n      );\n      return new ItemResponse(\n        response.result,\n        response.headers,\n        response.code,\n        response.substatus,\n        ref,\n        getEmptyCosmosDiagnostics(),\n      );\n    }, this.clientContext);\n  }\n\n  /**\n   * Upsert an item.\n   *\n   * There is no set schema for JSON items. They may contain any number of custom properties.\n   *\n   * @param body - Represents the body of the item. Can contain any number of user defined properties.\n   * @param options - Used for modifying the request (for instance, specifying the partition key).\n   */\n  public async upsert(\n    body: unknown,\n    options?: RequestOptions,\n  ): Promise<ItemResponse<ItemDefinition>>;\n  /**\n   * Upsert an item.\n   *\n   * Any provided type, T, is not necessarily enforced by the SDK.\n   * You may get more or less properties and it's up to your logic to enforce it.\n   *\n   * There is no set schema for JSON items. They may contain any number of custom properties.\n   *\n   * @param body - Represents the body of the item. Can contain any number of user defined properties.\n   * @param options - Used for modifying the request (for instance, specifying the partition key).\n   */\n  public async upsert<T extends ItemDefinition>(\n    body: T,\n    options?: RequestOptions,\n  ): Promise<ItemResponse<T>>;\n  public async upsert<T extends ItemDefinition>(\n    body: T,\n    options: RequestOptions = {},\n  ): Promise<ItemResponse<T>> {\n    return withDiagnostics(async (diagnosticNode: DiagnosticNodeInternal) => {\n      // Generate random document id if the id is missing in the payload and\n      // options.disableAutomaticIdGeneration != true\n      if ((body.id === undefined || body.id === \"\") && !options.disableAutomaticIdGeneration) {\n        body.id = randomUUID();\n      }\n\n      const partitionKeyDefinition = await readPartitionKeyDefinition(\n        diagnosticNode,\n        this.container,\n      );\n      const partitionKey = extractPartitionKeys(body, partitionKeyDefinition);\n\n      const err = {};\n      if (!isItemResourceValid(body, err)) {\n        throw err;\n      }\n\n      const path = getPathFromLink(this.container.url, ResourceType.item);\n      const id = getIdFromLink(this.container.url);\n\n      const response = await this.clientContext.upsert<T>({\n        body,\n        path,\n        resourceType: ResourceType.item,\n        resourceId: id,\n        options,\n        partitionKey,\n        diagnosticNode,\n      });\n\n      const ref = new Item(\n        this.container,\n        (response.result as any).id,\n        this.clientContext,\n        partitionKey,\n      );\n      return new ItemResponse(\n        response.result,\n        response.headers,\n        response.code,\n        response.substatus,\n        ref,\n        getEmptyCosmosDiagnostics(),\n      );\n    }, this.clientContext);\n  }\n\n  /**\n   * Execute bulk operations on items.\n   *\n   * Bulk takes an array of Operations which are typed based on what the operation does.\n   * The choices are: Create, Upsert, Read, Replace, and Delete\n   *\n   * Usage example:\n   * ```typescript\n   * // partitionKey is optional at the top level if present in the resourceBody\n   * const operations: OperationInput[] = [\n   *    {\n   *       operationType: \"Create\",\n   *       resourceBody: { id: \"doc1\", name: \"sample\", key: \"A\" }\n   *    },\n   *    {\n   *       operationType: \"Upsert\",\n   *       partitionKey: 'A',\n   *       resourceBody: { id: \"doc2\", name: \"other\", key: \"A\" }\n   *    }\n   * ]\n   *\n   * await database.container.items.bulk(operations)\n   * ```\n   *\n   * @param operations - List of operations. Limit 100\n   * @param bulkOptions - Optional options object to modify bulk behavior. Pass \\{ continueOnError: false \\} to stop executing operations when one fails. (Defaults to true)\n   * @param options - Used for modifying the request.\n   */\n  public async bulk(\n    operations: OperationInput[],\n    bulkOptions?: BulkOptions,\n    options?: RequestOptions,\n  ): Promise<BulkOperationResponse> {\n    return withDiagnostics(async (diagnosticNode: DiagnosticNodeInternal) => {\n      const partitionKeyRanges = (\n        await this.partitionKeyRangeCache.onCollectionRoutingMap(this.container.url, diagnosticNode)\n      ).getOrderedParitionKeyRanges();\n\n      const partitionKeyDefinition = await readPartitionKeyDefinition(\n        diagnosticNode,\n        this.container,\n      );\n      const batches: Batch[] = partitionKeyRanges.map((keyRange: PartitionKeyRange) => {\n        return {\n          min: keyRange.minInclusive,\n          max: keyRange.maxExclusive,\n          rangeId: keyRange.id,\n          indexes: [],\n          operations: [],\n        };\n      });\n\n      this.groupOperationsBasedOnPartitionKey(operations, partitionKeyDefinition, options, batches);\n\n      const path = getPathFromLink(this.container.url, ResourceType.item);\n\n      const orderedResponses: OperationResponse[] = [];\n      // split batches based on cumulative size of operations\n      const batchMap = batches\n        .filter((batch: Batch) => batch.operations.length)\n        .flatMap((batch: Batch) => splitBatchBasedOnBodySize(batch));\n\n      await Promise.all(\n        this.executeBatchOperations(\n          batchMap,\n          path,\n          bulkOptions,\n          options,\n          diagnosticNode,\n          orderedResponses,\n          partitionKeyDefinition,\n        ),\n      );\n      const response: any = orderedResponses;\n      response.diagnostics = diagnosticNode.toDiagnostic(this.clientContext.getClientConfig());\n      return response;\n    }, this.clientContext);\n  }\n\n  private executeBatchOperations(\n    batchMap: Batch[],\n    path: string,\n    bulkOptions: BulkOptions,\n    options: RequestOptions,\n    diagnosticNode: DiagnosticNodeInternal,\n    orderedResponses: OperationResponse[],\n    partitionKeyDefinition: PartitionKeyDefinition,\n  ): Promise<void>[] {\n    return batchMap.map(async (batch: Batch) => {\n      if (batch.operations.length > 100) {\n        throw new Error(\"Cannot run bulk request with more than 100 operations per partition\");\n      }\n      try {\n        const response = await addDignosticChild(\n          async (childNode: DiagnosticNodeInternal) =>\n            this.clientContext.bulk({\n              body: batch.operations,\n              partitionKeyRangeId: batch.rangeId,\n              path,\n              resourceId: this.container.url,\n              bulkOptions,\n              options,\n              diagnosticNode: childNode,\n            }),\n          diagnosticNode,\n          DiagnosticNodeType.BATCH_REQUEST,\n        );\n        response.result.forEach((operationResponse: OperationResponse, index: number) => {\n          orderedResponses[batch.indexes[index]] = operationResponse;\n        });\n      } catch (err: any) {\n        // In the case of 410 errors, we need to recompute the partition key ranges\n        // and redo the batch request, however, 410 errors occur for unsupported\n        // partition key types as well since we don't support them, so for now we throw\n        if (err.code === StatusCodes.Gone) {\n          const isPartitionSplit =\n            err.substatus === SubStatusCodes.PartitionKeyRangeGone ||\n            err.substatus === SubStatusCodes.CompletingSplit;\n\n          if (isPartitionSplit) {\n            const queryRange = new QueryRange(batch.min, batch.max, true, false);\n            const overlappingRanges = await this.partitionKeyRangeCache.getOverlappingRanges(\n              this.container.url,\n              queryRange,\n              diagnosticNode,\n              true,\n            );\n            if (overlappingRanges.length < 1) {\n              throw new Error(\"Partition split/merge detected but no overlapping ranges found.\");\n            }\n            // Handles both merge (overlappingRanges.length === 1) and split (overlappingRanges.length > 1) cases.\n            if (overlappingRanges.length >= 1) {\n              // const splitBatches: Batch[] = [];\n              const newBatches: Batch[] = this.createNewBatches(\n                overlappingRanges,\n                batch,\n                partitionKeyDefinition,\n              );\n\n              await Promise.all(\n                this.executeBatchOperations(\n                  newBatches,\n                  path,\n                  bulkOptions,\n                  options,\n                  diagnosticNode,\n                  orderedResponses,\n                  partitionKeyDefinition,\n                ),\n              );\n            }\n          } else {\n            throw new Error(\n              \"Partition key error. An operation has an unsupported partitionKey type\" +\n                err.message,\n            );\n          }\n        } else {\n          throw new Error(`Bulk request errored with: ${err.message}`);\n        }\n      }\n    });\n  }\n\n  /**\n   * Function to create new batches based of partition key Ranges.\n   *\n   * @param overlappingRanges - Overlapping partition key ranges.\n   * @param batch - Batch to be split.\n   * @param partitionKeyDefinition - PartitionKey definition of container.\n   * @returns Array of new batches.\n   */\n  private createNewBatches(\n    overlappingRanges: PartitionKeyRange[],\n    batch: Batch,\n    partitionKeyDefinition: PartitionKeyDefinition,\n  ): Batch[] {\n    const newBatches: Batch[] = overlappingRanges.map((keyRange: PartitionKeyRange) => {\n      return {\n        min: keyRange.minInclusive,\n        max: keyRange.maxExclusive,\n        rangeId: keyRange.id,\n        indexes: [],\n        operations: [],\n      };\n    });\n    let indexValue = 0;\n    batch.operations.forEach((operation) => {\n      const partitionKey = JSON.parse(operation.partitionKey);\n      const hashed = hashPartitionKey(\n        assertNotUndefined(\n          partitionKey,\n          \"undefined value for PartitionKey is not expected during grouping of bulk operations.\",\n        ),\n        partitionKeyDefinition,\n      );\n      const batchForKey = assertNotUndefined(\n        newBatches.find((newBatch: Batch) => {\n          return isKeyInRange(newBatch.min, newBatch.max, hashed);\n        }),\n        \"No suitable Batch found.\",\n      );\n      batchForKey.operations.push(operation);\n      batchForKey.indexes.push(batch.indexes[indexValue]);\n      indexValue++;\n    });\n    return newBatches;\n  }\n\n  /**\n   * Function to create batches based of partition key Ranges.\n   * @param operations - operations to group\n   * @param partitionDefinition - PartitionKey definition of container.\n   * @param options - Request options for bulk request.\n   * @param batches - Groups to be filled with operations.\n   */\n  private groupOperationsBasedOnPartitionKey(\n    operations: OperationInput[],\n    partitionDefinition: PartitionKeyDefinition,\n    options: RequestOptions | undefined,\n    batches: Batch[],\n  ) {\n    operations.forEach((operationInput, index: number) => {\n      const { operation, partitionKey } = prepareOperations(\n        operationInput,\n        partitionDefinition,\n        options,\n      );\n      const hashed = hashPartitionKey(\n        assertNotUndefined(\n          partitionKey,\n          \"undefined value for PartitionKey is not expected during grouping of bulk operations.\",\n        ),\n        partitionDefinition,\n      );\n      const batchForKey = assertNotUndefined(\n        batches.find((batch: Batch) => {\n          return isKeyInRange(batch.min, batch.max, hashed);\n        }),\n        \"No suitable Batch found.\",\n      );\n      batchForKey.operations.push(operation);\n      batchForKey.indexes.push(index);\n    });\n  }\n\n  /**\n   * Execute transactional batch operations on items.\n   *\n   * Batch takes an array of Operations which are typed based on what the operation does. Batch is transactional and will rollback all operations if one fails.\n   * The choices are: Create, Upsert, Read, Replace, and Delete\n   *\n   * Usage example:\n   * ```typescript\n   * // The partitionKey is a required second argument. If it’s undefined, it defaults to the expected partition key format.\n   * const operations: OperationInput[] = [\n   *    {\n   *       operationType: \"Create\",\n   *       resourceBody: { id: \"doc1\", name: \"sample\", key: \"A\" }\n   *    },\n   *    {\n   *       operationType: \"Upsert\",\n   *       resourceBody: { id: \"doc2\", name: \"other\", key: \"A\" }\n   *    }\n   * ]\n   *\n   * await database.container.items.batch(operations, \"A\")\n   * ```\n   *\n   * @param operations - List of operations. Limit 100\n   * @param options - Used for modifying the request\n   */\n  public async batch(\n    operations: OperationInput[],\n    partitionKey?: PartitionKey,\n    options?: RequestOptions,\n  ): Promise<Response<OperationResponse[]>> {\n    return withDiagnostics(async (diagnosticNode: DiagnosticNodeInternal) => {\n      operations.map((operation) => decorateBatchOperation(operation, options));\n      partitionKey = await setPartitionKeyIfUndefined(diagnosticNode, this.container, partitionKey);\n      const path = getPathFromLink(this.container.url, ResourceType.item);\n\n      if (operations.length > 100) {\n        throw new Error(\"Cannot run batch request with more than 100 operations per partition\");\n      }\n      try {\n        const response: Response<OperationResponse[]> = await this.clientContext.batch({\n          body: operations,\n          partitionKey,\n          path,\n          resourceId: this.container.url,\n          options,\n          diagnosticNode,\n        });\n        return response;\n      } catch (err: any) {\n        throw new Error(`Batch request error: ${err.message}`);\n      }\n    }, this.clientContext);\n  }\n}\n"],"mappings":"AAAA;AACA;AAEA,SAASA,kBAAkB,QAAQ,0BAA0B;AAG7D,SACEC,aAAa,EACbC,eAAe,EACfC,mBAAmB,EACnBC,YAAY,EACZC,WAAW,EACXC,cAAc,QACT,cAAc;AACrB,SAASC,oBAAoB,EAAEC,0BAA0B,QAAQ,2BAA2B;AAE5F,SAASC,aAAa,QAAQ,qBAAqB;AAGnD,SAASC,IAAI,QAAQ,QAAQ;AAE7B,SAASC,YAAY,QAAQ,gBAAgB;AAQ7C,SACEC,YAAY,EACZC,iBAAiB,EACjBC,sBAAsB,EACtBC,yBAAyB,QACpB,mBAAmB;AAC1B,SAASC,kBAAkB,EAAEC,4BAA4B,QAAQ,wBAAwB;AACzF,SAASC,gBAAgB,QAAQ,0BAA0B;AAE3D,SAASC,sBAAsB,EAAEC,UAAU,QAAQ,eAAe;AAKlE,SAASC,yBAAyB,QAAQ,yBAAyB;AACnE,SAASC,iCAAiC,QAAQ,yCAAyC;AAE3F,SAASC,kBAAkB,QAAQ,0CAA0C;AAC7E,SACEC,yBAAyB,EACzBC,eAAe,EACfC,iBAAiB,QACZ,yBAAyB;AAChC,SAASC,UAAU,QAAQ,kBAAkB;AAC7C,SAASC,0BAA0B,QAAQ,gBAAgB;AAE3D;;;AAGA,SAASC,mBAAmBA,CAACC,OAAgB;EAC3C,OAAOA,OAAO,IAAI,EAAEb,4BAA4B,CAACa,OAAO,CAAC,IAAIC,KAAK,CAACC,OAAO,CAACF,OAAO,CAAC,CAAC;AACtF;AAEA;;;;;AAKA,OAAM,MAAOG,KAAK;EAEhB;;;;;EAKAC,YACkBC,SAAoB,EACnBC,aAA4B;IAD7B,KAAAD,SAAS,GAATA,SAAS;IACR,KAAAC,aAAa,GAAbA,aAAa;IAE9B,IAAI,CAACC,sBAAsB,GAAG,IAAIlB,sBAAsB,CAAC,IAAI,CAACiB,aAAa,CAAC;EAC9E;EAkCOE,KAAKA,CAAIA,KAA4B,EAAER,OAAA,GAAuB,EAAE;IACrE,MAAMS,IAAI,GAAGrC,eAAe,CAAC,IAAI,CAACiC,SAAS,CAACK,GAAG,EAAEpC,YAAY,CAACqC,IAAI,CAAC;IACnE,MAAMC,EAAE,GAAGzC,aAAa,CAAC,IAAI,CAACkC,SAAS,CAACK,GAAG,CAAC;IAE5C,MAAMG,aAAa,GAA0B,MAAAA,CAC3CC,cAAsC,EACtCC,YAAyB,EACzBC,oBAA4B,KAC1B;MACF,MAAMC,QAAQ,GAAG,MAAM,IAAI,CAACX,aAAa,CAACY,SAAS,CAAC;QAClDT,IAAI;QACJU,YAAY,EAAE7C,YAAY,CAACqC,IAAI;QAC/BS,UAAU,EAAER,EAAE;QACdS,QAAQ,EAAGC,MAAM,IAAMA,MAAM,GAAGA,MAAM,CAACC,SAAS,GAAG,EAAG;QACtDf,KAAK;QACLR,OAAO,EAAEe,YAAY;QACrBS,YAAY,EAAExB,OAAO,CAACwB,YAAY;QAClCV,cAAc;QACdE,oBAAoB,EAAEA;OACvB,CAAC;MACF,OAAOC,QAAQ;IACjB,CAAC;IAED,OAAO,IAAItC,aAAa,CACtB,IAAI,CAAC2B,aAAa,EAClBE,KAAK,EACLR,OAAO,EACPa,aAAa,EACb,IAAI,CAACR,SAAS,CAACK,GAAG,EAClBpC,YAAY,CAACqC,IAAI,CAClB;EACH;EAsCOc,cAAcA,CACnBC,+BAAkE,EAClEC,iBAAqC;IAErC,IAAI5B,mBAAmB,CAAC2B,+BAA+B,CAAC,EAAE;MACxD,OAAO,IAAI,CAACE,UAAU,CAACF,+BAA+B,CAAC;IACzD,CAAC,MAAM;MACL,OAAO,IAAI,CAACE,UAAU,CAACF,+BAA+B,EAAEC,iBAAiB,CAAC;IAC5E;EACF;EAgCOC,UAAUA,CACfF,+BAAkE,EAClEC,iBAAqC;IAErC,IAAIH,YAA0B;IAC9B,IAAI,CAACG,iBAAiB,IAAI5B,mBAAmB,CAAC2B,+BAA+B,CAAC,EAAE;MAC9EF,YAAY,GAAGK,SAAS;MACxBF,iBAAiB,GAAGD,+BAA+B;IACrD,CAAC,MAAM,IACLA,+BAA+B,KAAKG,SAAS,IAC7C,CAAC9B,mBAAmB,CAAC2B,+BAA+B,CAAC,EACrD;MACAF,YAAY,GAAGE,+BAA+B;IAChD;IAEA,IAAI,CAACC,iBAAiB,EAAE;MACtBA,iBAAiB,GAAG,EAAE;IACxB;IAEA,MAAMlB,IAAI,GAAGrC,eAAe,CAAC,IAAI,CAACiC,SAAS,CAACK,GAAG,EAAEpC,YAAY,CAACqC,IAAI,CAAC;IACnE,MAAMC,EAAE,GAAGzC,aAAa,CAAC,IAAI,CAACkC,SAAS,CAACK,GAAG,CAAC;IAC5C,OAAO,IAAIxC,kBAAkB,CAAI,IAAI,CAACoC,aAAa,EAAEM,EAAE,EAAEH,IAAI,EAAEe,YAAY,EAAEG,iBAAiB,CAAC;EACjG;EAEA;;;EAGOG,qBAAqBA,CAC1BC,yBAAqD;IAErD,MAAMC,SAAS,GAAGD,yBAAyB,KAAKF,SAAS,GAAGE,yBAAyB,GAAG,EAAE;IAC1FvC,iCAAiC,CAACwC,SAAS,CAAC;IAC5C,MAAMC,QAAQ,GAAG1C,yBAAyB,CACxCyC,SAAS,EACT,IAAI,CAAC1B,aAAa,EAClB,IAAI,CAACD,SAAS,EACd,IAAI,CAACE,sBAAsB,CAC5B;IACD,OAAO0B,QAAQ;EACjB;EA6BOC,OAAOA,CAA2BlC,OAAqB;IAC5D,OAAO,IAAI,CAACQ,KAAK,CAAI,iBAAiB,EAAER,OAAO,CAAC;EAClD;EAEA;;;;;;;;;;;EAWO,MAAMmC,MAAMA,CACjBC,IAAO,EACPpC,OAAA,GAA0B,EAAE;IAE5B;IACA;IAEA,OAAOL,eAAe,CAAC,MAAOmB,cAAsC,IAAI;MACtE,IAAI,CAACsB,IAAI,CAACxB,EAAE,KAAKiB,SAAS,IAAIO,IAAI,CAACxB,EAAE,KAAK,EAAE,KAAK,CAACZ,OAAO,CAACqC,4BAA4B,EAAE;QACtFD,IAAI,CAACxB,EAAE,GAAGf,UAAU,EAAE;MACxB;MACA,MAAMyC,sBAAsB,GAAG,MAAMxC,0BAA0B,CAC7DgB,cAAc,EACd,IAAI,CAACT,SAAS,CACf;MACD,MAAMmB,YAAY,GAAG/C,oBAAoB,CAAC2D,IAAI,EAAEE,sBAAsB,CAAC;MAEvE,MAAMC,GAAG,GAAG,EAAE;MACd,IAAI,CAAClE,mBAAmB,CAAC+D,IAAI,EAAEG,GAAG,CAAC,EAAE;QACnC,MAAMA,GAAG;MACX;MAEA,MAAM9B,IAAI,GAAGrC,eAAe,CAAC,IAAI,CAACiC,SAAS,CAACK,GAAG,EAAEpC,YAAY,CAACqC,IAAI,CAAC;MACnE,MAAMC,EAAE,GAAGzC,aAAa,CAAC,IAAI,CAACkC,SAAS,CAACK,GAAG,CAAC;MAE5C,MAAMO,QAAQ,GAAG,MAAM,IAAI,CAACX,aAAa,CAAC6B,MAAM,CAAI;QAClDC,IAAI;QACJ3B,IAAI;QACJU,YAAY,EAAE7C,YAAY,CAACqC,IAAI;QAC/BS,UAAU,EAAER,EAAE;QACdE,cAAc;QACdd,OAAO;QACPwB;OACD,CAAC;MAEF,MAAMgB,GAAG,GAAG,IAAI5D,IAAI,CAClB,IAAI,CAACyB,SAAS,EACbY,QAAQ,CAACK,MAAc,CAACV,EAAE,EAC3B,IAAI,CAACN,aAAa,EAClBkB,YAAY,CACb;MACD,OAAO,IAAI3C,YAAY,CACrBoC,QAAQ,CAACK,MAAM,EACfL,QAAQ,CAACwB,OAAO,EAChBxB,QAAQ,CAACyB,IAAI,EACbzB,QAAQ,CAAC0B,SAAS,EAClBH,GAAG,EACH9C,yBAAyB,EAAE,CAC5B;IACH,CAAC,EAAE,IAAI,CAACY,aAAa,CAAC;EACxB;EA6BO,MAAMsC,MAAMA,CACjBR,IAAO,EACPpC,OAAA,GAA0B,EAAE;IAE5B,OAAOL,eAAe,CAAC,MAAOmB,cAAsC,IAAI;MACtE;MACA;MACA,IAAI,CAACsB,IAAI,CAACxB,EAAE,KAAKiB,SAAS,IAAIO,IAAI,CAACxB,EAAE,KAAK,EAAE,KAAK,CAACZ,OAAO,CAACqC,4BAA4B,EAAE;QACtFD,IAAI,CAACxB,EAAE,GAAGf,UAAU,EAAE;MACxB;MAEA,MAAMyC,sBAAsB,GAAG,MAAMxC,0BAA0B,CAC7DgB,cAAc,EACd,IAAI,CAACT,SAAS,CACf;MACD,MAAMmB,YAAY,GAAG/C,oBAAoB,CAAC2D,IAAI,EAAEE,sBAAsB,CAAC;MAEvE,MAAMC,GAAG,GAAG,EAAE;MACd,IAAI,CAAClE,mBAAmB,CAAC+D,IAAI,EAAEG,GAAG,CAAC,EAAE;QACnC,MAAMA,GAAG;MACX;MAEA,MAAM9B,IAAI,GAAGrC,eAAe,CAAC,IAAI,CAACiC,SAAS,CAACK,GAAG,EAAEpC,YAAY,CAACqC,IAAI,CAAC;MACnE,MAAMC,EAAE,GAAGzC,aAAa,CAAC,IAAI,CAACkC,SAAS,CAACK,GAAG,CAAC;MAE5C,MAAMO,QAAQ,GAAG,MAAM,IAAI,CAACX,aAAa,CAACsC,MAAM,CAAI;QAClDR,IAAI;QACJ3B,IAAI;QACJU,YAAY,EAAE7C,YAAY,CAACqC,IAAI;QAC/BS,UAAU,EAAER,EAAE;QACdZ,OAAO;QACPwB,YAAY;QACZV;OACD,CAAC;MAEF,MAAM0B,GAAG,GAAG,IAAI5D,IAAI,CAClB,IAAI,CAACyB,SAAS,EACbY,QAAQ,CAACK,MAAc,CAACV,EAAE,EAC3B,IAAI,CAACN,aAAa,EAClBkB,YAAY,CACb;MACD,OAAO,IAAI3C,YAAY,CACrBoC,QAAQ,CAACK,MAAM,EACfL,QAAQ,CAACwB,OAAO,EAChBxB,QAAQ,CAACyB,IAAI,EACbzB,QAAQ,CAAC0B,SAAS,EAClBH,GAAG,EACH9C,yBAAyB,EAAE,CAC5B;IACH,CAAC,EAAE,IAAI,CAACY,aAAa,CAAC;EACxB;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA4BO,MAAMuC,IAAIA,CACfC,UAA4B,EAC5BC,WAAyB,EACzB/C,OAAwB;IAExB,OAAOL,eAAe,CAAC,MAAOmB,cAAsC,IAAI;MACtE,MAAMkC,kBAAkB,GAAG,CACzB,MAAM,IAAI,CAACzC,sBAAsB,CAAC0C,sBAAsB,CAAC,IAAI,CAAC5C,SAAS,CAACK,GAAG,EAAEI,cAAc,CAAC,EAC5FoC,2BAA2B,EAAE;MAE/B,MAAMZ,sBAAsB,GAAG,MAAMxC,0BAA0B,CAC7DgB,cAAc,EACd,IAAI,CAACT,SAAS,CACf;MACD,MAAM8C,OAAO,GAAYH,kBAAkB,CAACI,GAAG,CAAEC,QAA2B,IAAI;QAC9E,OAAO;UACLC,GAAG,EAAED,QAAQ,CAACE,YAAY;UAC1BC,GAAG,EAAEH,QAAQ,CAACI,YAAY;UAC1BC,OAAO,EAAEL,QAAQ,CAACzC,EAAE;UACpB+C,OAAO,EAAE,EAAE;UACXb,UAAU,EAAE;SACb;MACH,CAAC,CAAC;MAEF,IAAI,CAACc,kCAAkC,CAACd,UAAU,EAAER,sBAAsB,EAAEtC,OAAO,EAAEmD,OAAO,CAAC;MAE7F,MAAM1C,IAAI,GAAGrC,eAAe,CAAC,IAAI,CAACiC,SAAS,CAACK,GAAG,EAAEpC,YAAY,CAACqC,IAAI,CAAC;MAEnE,MAAMkD,gBAAgB,GAAwB,EAAE;MAChD;MACA,MAAMC,QAAQ,GAAGX,OAAO,CACrBY,MAAM,CAAEC,KAAY,IAAKA,KAAK,CAAClB,UAAU,CAACmB,MAAM,CAAC,CACjDC,OAAO,CAAEF,KAAY,IAAK/E,yBAAyB,CAAC+E,KAAK,CAAC,CAAC;MAE9D,MAAMG,OAAO,CAACC,GAAG,CACf,IAAI,CAACC,sBAAsB,CACzBP,QAAQ,EACRrD,IAAI,EACJsC,WAAW,EACX/C,OAAO,EACPc,cAAc,EACd+C,gBAAgB,EAChBvB,sBAAsB,CACvB,CACF;MACD,MAAMrB,QAAQ,GAAQ4C,gBAAgB;MACtC5C,QAAQ,CAACqD,WAAW,GAAGxD,cAAc,CAACyD,YAAY,CAAC,IAAI,CAACjE,aAAa,CAACkE,eAAe,EAAE,CAAC;MACxF,OAAOvD,QAAQ;IACjB,CAAC,EAAE,IAAI,CAACX,aAAa,CAAC;EACxB;EAEQ+D,sBAAsBA,CAC5BP,QAAiB,EACjBrD,IAAY,EACZsC,WAAwB,EACxB/C,OAAuB,EACvBc,cAAsC,EACtC+C,gBAAqC,EACrCvB,sBAA8C;IAE9C,OAAOwB,QAAQ,CAACV,GAAG,CAAC,MAAOY,KAAY,IAAI;MACzC,IAAIA,KAAK,CAAClB,UAAU,CAACmB,MAAM,GAAG,GAAG,EAAE;QACjC,MAAM,IAAIQ,KAAK,CAAC,qEAAqE,CAAC;MACxF;MACA,IAAI;QACF,MAAMxD,QAAQ,GAAG,MAAMrB,iBAAiB,CACtC,MAAO8E,SAAiC,IACtC,IAAI,CAACpE,aAAa,CAACuC,IAAI,CAAC;UACtBT,IAAI,EAAE4B,KAAK,CAAClB,UAAU;UACtB6B,mBAAmB,EAAEX,KAAK,CAACN,OAAO;UAClCjD,IAAI;UACJW,UAAU,EAAE,IAAI,CAACf,SAAS,CAACK,GAAG;UAC9BqC,WAAW;UACX/C,OAAO;UACPc,cAAc,EAAE4D;SACjB,CAAC,EACJ5D,cAAc,EACdrB,kBAAkB,CAACmF,aAAa,CACjC;QACD3D,QAAQ,CAACK,MAAM,CAACuD,OAAO,CAAC,CAACC,iBAAoC,EAAEC,KAAa,KAAI;UAC9ElB,gBAAgB,CAACG,KAAK,CAACL,OAAO,CAACoB,KAAK,CAAC,CAAC,GAAGD,iBAAiB;QAC5D,CAAC,CAAC;MACJ,CAAC,CAAC,OAAOvC,GAAQ,EAAE;QACjB;QACA;QACA;QACA,IAAIA,GAAG,CAACG,IAAI,KAAKnE,WAAW,CAACyG,IAAI,EAAE;UACjC,MAAMC,gBAAgB,GACpB1C,GAAG,CAACI,SAAS,KAAKnE,cAAc,CAAC0G,qBAAqB,IACtD3C,GAAG,CAACI,SAAS,KAAKnE,cAAc,CAAC2G,eAAe;UAElD,IAAIF,gBAAgB,EAAE;YACpB,MAAMG,UAAU,GAAG,IAAI9F,UAAU,CAAC0E,KAAK,CAACV,GAAG,EAAEU,KAAK,CAACR,GAAG,EAAE,IAAI,EAAE,KAAK,CAAC;YACpE,MAAM6B,iBAAiB,GAAG,MAAM,IAAI,CAAC9E,sBAAsB,CAAC+E,oBAAoB,CAC9E,IAAI,CAACjF,SAAS,CAACK,GAAG,EAClB0E,UAAU,EACVtE,cAAc,EACd,IAAI,CACL;YACD,IAAIuE,iBAAiB,CAACpB,MAAM,GAAG,CAAC,EAAE;cAChC,MAAM,IAAIQ,KAAK,CAAC,iEAAiE,CAAC;YACpF;YACA;YACA,IAAIY,iBAAiB,CAACpB,MAAM,IAAI,CAAC,EAAE;cACjC;cACA,MAAMsB,UAAU,GAAY,IAAI,CAACC,gBAAgB,CAC/CH,iBAAiB,EACjBrB,KAAK,EACL1B,sBAAsB,CACvB;cAED,MAAM6B,OAAO,CAACC,GAAG,CACf,IAAI,CAACC,sBAAsB,CACzBkB,UAAU,EACV9E,IAAI,EACJsC,WAAW,EACX/C,OAAO,EACPc,cAAc,EACd+C,gBAAgB,EAChBvB,sBAAsB,CACvB,CACF;YACH;UACF,CAAC,MAAM;YACL,MAAM,IAAImC,KAAK,CACb,wEAAwE,GACtElC,GAAG,CAACkD,OAAO,CACd;UACH;QACF,CAAC,MAAM;UACL,MAAM,IAAIhB,KAAK,CAAC,8BAA8BlC,GAAG,CAACkD,OAAO,EAAE,CAAC;QAC9D;MACF;IACF,CAAC,CAAC;EACJ;EAEA;;;;;;;;EAQQD,gBAAgBA,CACtBH,iBAAsC,EACtCrB,KAAY,EACZ1B,sBAA8C;IAE9C,MAAMiD,UAAU,GAAYF,iBAAiB,CAACjC,GAAG,CAAEC,QAA2B,IAAI;MAChF,OAAO;QACLC,GAAG,EAAED,QAAQ,CAACE,YAAY;QAC1BC,GAAG,EAAEH,QAAQ,CAACI,YAAY;QAC1BC,OAAO,EAAEL,QAAQ,CAACzC,EAAE;QACpB+C,OAAO,EAAE,EAAE;QACXb,UAAU,EAAE;OACb;IACH,CAAC,CAAC;IACF,IAAI4C,UAAU,GAAG,CAAC;IAClB1B,KAAK,CAAClB,UAAU,CAAC+B,OAAO,CAAEc,SAAS,IAAI;MACrC,MAAMnE,YAAY,GAAGoE,IAAI,CAACC,KAAK,CAACF,SAAS,CAACnE,YAAY,CAAC;MACvD,MAAMsE,MAAM,GAAG1G,gBAAgB,CAC7BF,kBAAkB,CAChBsC,YAAY,EACZ,sFAAsF,CACvF,EACDc,sBAAsB,CACvB;MACD,MAAMyD,WAAW,GAAG7G,kBAAkB,CACpCqG,UAAU,CAACS,IAAI,CAAEC,QAAe,IAAI;QAClC,OAAOnH,YAAY,CAACmH,QAAQ,CAAC3C,GAAG,EAAE2C,QAAQ,CAACzC,GAAG,EAAEsC,MAAM,CAAC;MACzD,CAAC,CAAC,EACF,0BAA0B,CAC3B;MACDC,WAAW,CAACjD,UAAU,CAACoD,IAAI,CAACP,SAAS,CAAC;MACtCI,WAAW,CAACpC,OAAO,CAACuC,IAAI,CAAClC,KAAK,CAACL,OAAO,CAAC+B,UAAU,CAAC,CAAC;MACnDA,UAAU,EAAE;IACd,CAAC,CAAC;IACF,OAAOH,UAAU;EACnB;EAEA;;;;;;;EAOQ3B,kCAAkCA,CACxCd,UAA4B,EAC5BqD,mBAA2C,EAC3CnG,OAAmC,EACnCmD,OAAgB;IAEhBL,UAAU,CAAC+B,OAAO,CAAC,CAACuB,cAAc,EAAErB,KAAa,KAAI;MACnD,MAAM;QAAEY,SAAS;QAAEnE;MAAY,CAAE,GAAGzC,iBAAiB,CACnDqH,cAAc,EACdD,mBAAmB,EACnBnG,OAAO,CACR;MACD,MAAM8F,MAAM,GAAG1G,gBAAgB,CAC7BF,kBAAkB,CAChBsC,YAAY,EACZ,sFAAsF,CACvF,EACD2E,mBAAmB,CACpB;MACD,MAAMJ,WAAW,GAAG7G,kBAAkB,CACpCiE,OAAO,CAAC6C,IAAI,CAAEhC,KAAY,IAAI;QAC5B,OAAOlF,YAAY,CAACkF,KAAK,CAACV,GAAG,EAAEU,KAAK,CAACR,GAAG,EAAEsC,MAAM,CAAC;MACnD,CAAC,CAAC,EACF,0BAA0B,CAC3B;MACDC,WAAW,CAACjD,UAAU,CAACoD,IAAI,CAACP,SAAS,CAAC;MACtCI,WAAW,CAACpC,OAAO,CAACuC,IAAI,CAACnB,KAAK,CAAC;IACjC,CAAC,CAAC;EACJ;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;EA0BO,MAAMf,KAAKA,CAChBlB,UAA4B,EAC5BtB,YAA2B,EAC3BxB,OAAwB;IAExB,OAAOL,eAAe,CAAC,MAAOmB,cAAsC,IAAI;MACtEgC,UAAU,CAACM,GAAG,CAAEuC,SAAS,IAAK3G,sBAAsB,CAAC2G,SAAS,EAAE3F,OAAO,CAAC,CAAC;MACzEwB,YAAY,GAAG,MAAM9C,0BAA0B,CAACoC,cAAc,EAAE,IAAI,CAACT,SAAS,EAAEmB,YAAY,CAAC;MAC7F,MAAMf,IAAI,GAAGrC,eAAe,CAAC,IAAI,CAACiC,SAAS,CAACK,GAAG,EAAEpC,YAAY,CAACqC,IAAI,CAAC;MAEnE,IAAImC,UAAU,CAACmB,MAAM,GAAG,GAAG,EAAE;QAC3B,MAAM,IAAIQ,KAAK,CAAC,sEAAsE,CAAC;MACzF;MACA,IAAI;QACF,MAAMxD,QAAQ,GAAkC,MAAM,IAAI,CAACX,aAAa,CAAC0D,KAAK,CAAC;UAC7E5B,IAAI,EAAEU,UAAU;UAChBtB,YAAY;UACZf,IAAI;UACJW,UAAU,EAAE,IAAI,CAACf,SAAS,CAACK,GAAG;UAC9BV,OAAO;UACPc;SACD,CAAC;QACF,OAAOG,QAAQ;MACjB,CAAC,CAAC,OAAOsB,GAAQ,EAAE;QACjB,MAAM,IAAIkC,KAAK,CAAC,wBAAwBlC,GAAG,CAACkD,OAAO,EAAE,CAAC;MACxD;IACF,CAAC,EAAE,IAAI,CAACnF,aAAa,CAAC;EACxB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}